{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding - Project 4 of Udacity's Self-Driving Car Nanodegree\n",
    "\n",
    "1. Camera Calibration\n",
    "2. Distortion correction\n",
    "3. Image inspection\n",
    "4. Perspective correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ntpath\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "col_count = 3\n",
    "row_count = 7\n",
    "fig = plt.figure(figsize=(16,32))\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Step throuagh the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "        plt.imshow(img)\n",
    "        index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "fig = plt.figure(figsize=(16,32))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    plt.imshow(img)\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example image inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = ['test_images/test1.jpg', 'test_images/test2.jpg', 'test_images/test3.jpg',\n",
    "          'test_images/test4.jpg', 'test_images/test5.jpg', 'test_images/test6.jpg',\n",
    "          'test_images/straight_lines1.jpg', 'test_images/straight_lines2.jpg']\n",
    "\n",
    "example_images = images\n",
    "\n",
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "\n",
    "index = 0\n",
    "\n",
    "example_image = None\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+1)\n",
    "    plt.imshow(img)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+2)\n",
    "    plt.imshow(img)\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perspective correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_image = cv2.imread(example_images[6])\n",
    "example_image = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n",
    "example_image = cv2.undistort(example_image, mtx, dist, None, mtx)\n",
    "\n",
    "img_size = (example_image.shape[1],example_image.shape[0])\n",
    "\n",
    "# defines the perspective of the camera image by defining points near the front of the car and close the the\n",
    "# center of the image\n",
    "relation_factor = 13.5/1.92\n",
    "front_perspective_div = 3.5\n",
    "back_perspective_div = front_perspective_div*relation_factor\n",
    "front_perspective_y_perc = 0.92\n",
    "back_perspective_y_perc = 0.63\n",
    "\n",
    "# trapez points in order bottom left, top left, top right, bottom right (front, back, back, front)\n",
    "src = [(int(img_size[0]/2-img_size[0]/front_perspective_div), int(img_size[1]*front_perspective_y_perc)), \n",
    "       (int(img_size[0]/2-img_size[0]/back_perspective_div), int(img_size[1]*back_perspective_y_perc)), \n",
    "       (int(img_size[0]/2+img_size[0]/back_perspective_div), int(img_size[1]*back_perspective_y_perc)),\n",
    "       (int(img_size[0]/2+img_size[0]/front_perspective_div), int(img_size[1]*front_perspective_y_perc))]\n",
    "\n",
    "# paint trapez into the image\n",
    "image_copy = np.copy(example_image)\n",
    "\n",
    "for index in range(4):\n",
    "    pa = src[index]\n",
    "    pb = src[(index+1)%4]\n",
    "    cv2.line(image_copy, pa, pb, (255,0,0), 4)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.imshow(image_copy)\n",
    "\n",
    "margin_factor = 6\n",
    "\n",
    "dst = [(img_size[0]//margin_factor, img_size[1]), \n",
    "       (img_size[0]//margin_factor, 0), \n",
    "       (img_size[0]-img_size[0]//margin_factor, 0), \n",
    "       (img_size[0]-img_size[0]//margin_factor, img_size[1]), \n",
    "       ]\n",
    "\n",
    "src = np.array(src, dtype=np.float32)\n",
    "dst = np.array(dst, dtype=np.float32)\n",
    "\n",
    "tmx = cv2.getPerspectiveTransform(np.array(src), np.array(dst))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "width = image_copy.shape[1]\n",
    "height = image_copy.shape[0]\n",
    "\n",
    "warped = cv2.warpPerspective(example_image, tmx, (width, height))\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "project_video = \"project_video.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video of the project video after distortion and perspective correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    warped = cv2.warpPerspective(undistorted, tmx, (width, height))\n",
    "    return warped\n",
    "    \n",
    "from_above_video = 'test_videos_output/from_above.mp4'\n",
    "\n",
    "white_output = from_above_video\n",
    "clip1 = VideoFileClip(project_video)\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(from_above_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    plt.title(ntpath.basename(fname))\n",
    "    warped = cv2.warpPerspective(img, tmx, (width, height))\n",
    "    plt.imshow(warped, 'gray')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hls_threshold_mask(image, thresh=(95,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    s = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s>=thresh[0]) & (s<=thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def sobel_mag_mask(image, thresh=(10,255), kernel_size=3):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_sobelxy = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    eight_bit = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(abs_sobelxy)\n",
    "    binary_output[(eight_bit >= thresh[0]) & (eight_bit <= thresh[1])] = 1    \n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def sobel_dir_mask(image, thresh=(0.7, 1.3), kernel_size=13):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_x = np.abs(sobel_x)\n",
    "    abs_y = np.abs(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    sob_dir = np.arctan2(abs_y, abs_x)\n",
    "    # 5) Create a binary mask where direction thresholds are met    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(sob_dir)\n",
    "    binary_output[(sob_dir>=thresh[0]) & (sob_dir<=thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def create_binary_mask(image):\n",
    "    hls_thresh = hls_threshold_mask(image)\n",
    "    sobel_mag = sobel_mag_mask(image)\n",
    "    sobel_dir = sobel_dir_mask(image)\n",
    "    \n",
    "    binary_output = np.zeros_like(sobel_dir)\n",
    "    binary_output[(hls_thresh==1)] = 1.0\n",
    "#    binary_output[(hls_thresh==1) | ((sobel_mag==1) & (sobel_dir==1))] = 1\n",
    "    ## binary_output[(hls_thresh==1)] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # img = sobel_mag_mask(img)\n",
    "    img = create_binary_mask(img)\n",
    "    plt.title(ntpath.basename(fname))\n",
    "    warped = cv2.warpPerspective(img, tmx, (width, height))\n",
    "    plt.imshow(warped, 'gray')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # img = sobel_mag_mask(img)\n",
    "    img = create_binary_mask(img)\n",
    "    plt.title(ntpath.basename(fname))\n",
    "    warped = cv2.warpPerspective(img, tmx, (width, height))\n",
    "    histogram = np.sum(warped[img.shape[0]//2:,:], axis=0)\n",
    "    plt.plot(histogram)\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class lane_finder:\n",
    "    def __init__(self):\n",
    "        self.last_base_left = None\n",
    "        self.last_base_right = None\n",
    "        self.hist_minimum_thresh = 30\n",
    "        self.hist_perf_thresh = 60\n",
    "        self.lane_size = None\n",
    "        self.perfect_pix_win = 140\n",
    "    \n",
    "    def find_lanes_using_window(self, img):\n",
    "        sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        binary_warped = create_binary_mask(img)\n",
    "        binary_warped = cv2.warpPerspective(binary_warped, tmx, (width, height))    \n",
    "\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "                \n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        \n",
    "        if histogram[leftx_base]<=self.hist_minimum_thresh and self.last_base_left is not None:\n",
    "            leftx_base = self.last_base_left\n",
    "        else:\n",
    "            self.last_base_left = leftx_base\n",
    "        \n",
    "        if histogram[rightx_base]<=self.hist_minimum_thresh and self.last_base_right is not None:\n",
    "            rightx_base = self.last_base_right\n",
    "        else:\n",
    "            self.last_base_right = rightx_base\n",
    "\n",
    "        # if we can right now perfectly detect both lanes recalibrate the lane size\n",
    "        if histogram[leftx_base]>=self.hist_perf_thresh and histogram[rightx_base]>=self.hist_perf_thresh:\n",
    "            self.lane_size = rightx_base-leftx_base\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        \n",
    "        dominant_l = False\n",
    "        dominant_r = False\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            \n",
    "            color_l = (0,255,0)\n",
    "            color_r = (0,255,0)\n",
    "            \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "                \n",
    "            if len(good_left_inds)>self.perfect_pix_win:\n",
    "                dominant_l = True\n",
    "            else:\n",
    "                dominant_l = False\n",
    "                \n",
    "            if len(good_right_inds)>self.perfect_pix_win:\n",
    "                dominant_r = True\n",
    "            else:\n",
    "                dominant_r = False\n",
    "\n",
    "            if dominant_l:\n",
    "                color_l = (255,0,0)                \n",
    "            if dominant_r:\n",
    "                color_r = (255,0,0)                            \n",
    "\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            color_l, 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            color_r, 2) \n",
    "                \n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = None\n",
    "        right_fit = None\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "\n",
    "        if leftx.shape[0]!=0 and lefty.shape!=0:\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        if rightx.shape[0]!=0 and righty.shape!=0:\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        out_img = out_img.astype(np.ubyte)\n",
    "\n",
    "        return out_img\n",
    "\n",
    "for cur_fn in example_images:\n",
    "    img = cv2.imread(cur_fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    lf = lane_finder()\n",
    "    out_img = lf.find_lanes_using_window(img)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    plt.imshow(out_img)\n",
    "#    plt.plot(left_fitx, ploty, color='yellow')\n",
    "#    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lf = lane_finder()\n",
    "\n",
    "def process_image(image):\n",
    "    warped = lf.find_lanes_using_window(image)\n",
    "    return warped\n",
    "    \n",
    "find_lanes_raw = 'test_videos_output/find_lanes_raw.mp4'\n",
    "\n",
    "white_output = find_lanes_raw\n",
    "clip1 = VideoFileClip(project_video)\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(find_lanes_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepl35]",
   "language": "python",
   "name": "conda-env-deepl35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
