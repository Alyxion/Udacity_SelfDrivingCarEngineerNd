{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding - Project 4 of Udacity's Self-Driving Car Nanodegree\n",
    "\n",
    "1. Camera Calibration\n",
    "2. Distortion correction\n",
    "3. Image inspection\n",
    "4. Perspective correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ntpath\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "col_count = 3\n",
    "row_count = 7\n",
    "fig = plt.figure(figsize=(16,32))\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Step throuagh the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "        plt.imshow(img)\n",
    "        index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "fig = plt.figure(figsize=(16,32))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    plt.imshow(img)\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example image inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "example_images = images\n",
    "\n",
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "\n",
    "index = 0\n",
    "\n",
    "example_image = None\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+1)\n",
    "    plt.imshow(img)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+2)\n",
    "    plt.imshow(img)\n",
    "    example_image = img\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perspective correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (example_image.shape[1],example_image.shape[0])\n",
    "\n",
    "# defines the perspective of the camera image by defining points near the front of the car and close the the\n",
    "# center of the image\n",
    "relation_factor = 13.5/2.8\n",
    "front_perspective_div = 3.5\n",
    "back_perspective_div = front_perspective_div*relation_factor\n",
    "front_perspective_y_perc = 0.92\n",
    "back_perspective_y_perc = 0.65\n",
    "\n",
    "# trapez points in order bottom left, top left, top right, bottom right (front, back, back, front)\n",
    "src = [(int(img_size[0]/2-img_size[0]/front_perspective_div), int(img_size[1]*front_perspective_y_perc)), \n",
    "       (int(img_size[0]/2-img_size[0]/back_perspective_div), int(img_size[1]*back_perspective_y_perc)), \n",
    "       (int(img_size[0]/2+img_size[0]/back_perspective_div), int(img_size[1]*back_perspective_y_perc)),\n",
    "       (int(img_size[0]/2+img_size[0]/front_perspective_div), int(img_size[1]*front_perspective_y_perc))]\n",
    "\n",
    "# paint trapez into the image\n",
    "image_copy = np.copy(example_image)\n",
    "\n",
    "for index in range(4):\n",
    "    pa = src[index]\n",
    "    pb = src[(index+1)%4]\n",
    "    cv2.line(image_copy, pa, pb, (255,0,0), 4)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.imshow(image_copy)\n",
    "\n",
    "margin_factor = 3\n",
    "\n",
    "dst = [(img_size[0]//margin_factor, img_size[1]), \n",
    "       (img_size[0]//margin_factor, 0), \n",
    "       (img_size[0]-img_size[0]//margin_factor, 0), \n",
    "       (img_size[0]-img_size[0]//margin_factor, img_size[1]), \n",
    "       ]\n",
    "\n",
    "src = np.array(src, dtype=np.float32)\n",
    "dst = np.array(dst, dtype=np.float32)\n",
    "\n",
    "tmx = cv2.getPerspectiveTransform(np.array(src), np.array(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = image_copy.shape[1]\n",
    "height = image_copy.shape[0]\n",
    "\n",
    "warped = cv2.warpPerspective(example_image, tmx, (width, height))\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "project_video = \"project_video.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video of the project video after distortion and perspective correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    warped = cv2.warpPerspective(undistorted, tmx, (width, height))\n",
    "    return warped\n",
    "    \n",
    "from_above_video = 'test_videos_output/from_above.mp4'\n",
    "\n",
    "white_output = from_above_video\n",
    "clip1 = VideoFileClip(project_video)\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(from_above_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+1)\n",
    "    plt.imshow(img)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = create_binary_mask(img)\n",
    "    sp = fig.add_subplot(row_count, col_count, index*2+2)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_threshold_mask(image, thresh=(80,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    s = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s>=thresh[0]) & (s<=thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def sobel_mag_mask(image, thresh=(10,255), kernel_size=7):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_sobelxy = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    eight_bit = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(abs_sobelxy)\n",
    "    binary_output[(eight_bit >= thresh[0]) & (eight_bit <= thresh[1])] = 1    \n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def sobel_dir_mask(image, thresh=(0.7, 1.3), kernel_size=9):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_x = np.abs(sobel_x)\n",
    "    abs_y = np.abs(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    sob_dir = np.arctan2(abs_y, abs_x)\n",
    "    # 5) Create a binary mask where direction thresholds are met    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(sob_dir)\n",
    "    binary_output[(sob_dir>=thresh[0]) & (sob_dir<=thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def create_binary_mask(image):\n",
    "    hls_thresh = hls_threshold_mask(image)\n",
    "    sobel_mag = sobel_mag_mask(image)\n",
    "    sobel_dir = sobel_dir_mask(image)\n",
    "    \n",
    "    binary_output = np.zeros_like(sobel_dir)\n",
    "    binary_output[(sobel_dir==1) & (hls_thresh==1) & (sobel_mag==1)] = 1\n",
    "#    binary_output[(sobel_dir==1) & (hls_thresh==1)] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "col_count = 2\n",
    "row_count = 8\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "index = 0\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in example_images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    sp = fig.add_subplot(row_count, col_count, index+1)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # img = sobel_mag_mask(img)\n",
    "    img = create_binary_mask(img)\n",
    "    plt.title(ntpath.basename(fname))\n",
    "    warped = cv2.warpPerspective(img, tmx, (width, height))\n",
    "    plt.imshow(warped, 'gray')\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepl35]",
   "language": "python",
   "name": "conda-env-deepl35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
